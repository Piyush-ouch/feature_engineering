{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQhvqWezbxE1",
        "outputId": "ed871b42-a01a-44a8-c130-78fdfee3f2a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'time-series-datasets' dataset.\n",
            "Path to dataset files: /kaggle/input/time-series-datasets\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"shenba/time-series-datasets\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Electric Production Data Preprocessing\n",
        "# ================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load dataset (adjust the path as per your Colab output)\n",
        "df = pd.read_csv(\"/root/.cache/kagglehub/datasets/shenba/time-series-datasets/versions/1/Electric_Production.csv\")\n",
        "\n",
        "print(\"---- Dataset Info ----\")\n",
        "print(df.info(), \"\\n\")\n",
        "\n",
        "print(\"---- Missing Values ----\")\n",
        "print(df.isnull().sum(), \"\\n\")\n",
        "\n",
        "# Handle missing data (if any)\n",
        "df.fillna(df.mean(numeric_only=True), inplace=True)\n",
        "\n",
        "# Add derived time features (if needed)\n",
        "# You already have Year, Month, Quarter — so we’ll keep them as they are.\n",
        "\n",
        "# Check for categorical columns\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "print(\"Categorical columns:\", categorical_cols, \"\\n\")\n",
        "\n",
        "# Encode categorical variables (if any exist)\n",
        "if len(categorical_cols) > 0:\n",
        "    encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
        "    encoded = encoder.fit_transform(df[categorical_cols])\n",
        "    encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out(categorical_cols))\n",
        "    df = pd.concat([df.drop(columns=categorical_cols), encoded_df], axis=1)\n",
        "else:\n",
        "    print(\"No categorical columns to encode.\\n\")\n",
        "\n",
        "# Feature Scaling (Standardization)\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(df)\n",
        "\n",
        "scaled_df = pd.DataFrame(scaled_data, columns=df.columns)\n",
        "print(\"After Scaling:\\n\", scaled_df.head(), \"\\n\")\n",
        "\n",
        "# Dimensionality Reduction (PCA)\n",
        "pca = PCA(n_components=2)\n",
        "pca_features = pca.fit_transform(scaled_data)\n",
        "pca_df = pd.DataFrame(pca_features, columns=['PC1', 'PC2'])\n",
        "print(\"Explained Variance Ratio (PCA):\", pca.explained_variance_ratio_, \"\\n\")\n",
        "\n",
        "# Feature Selection (SelectKBest)\n",
        "X = df.drop(columns=['IPG2211A2N'])\n",
        "y = df['IPG2211A2N']\n",
        "\n",
        "selector = SelectKBest(score_func=f_regression, k='all')\n",
        "selector.fit(X, y)\n",
        "scores = pd.DataFrame({'Feature': X.columns, 'Score': selector.scores_})\n",
        "print(\"Feature Selection Scores:\\n\", scores.sort_values(by='Score', ascending=False), \"\\n\")\n",
        "\n",
        "# Summary of Transformations\n",
        "print(\"\"\"\n",
        "==================== SUMMARY ====================\n",
        "Missing values handled using mean imputation (if any).\n",
        "No categorical encoding was needed (dataset fully numeric).\n",
        "Feature scaling applied using StandardScaler (Z-score normalization).\n",
        "PCA reduced dataset to 2 principal components for visualization.\n",
        "Feature selection (SelectKBest) showed importance scores of numeric features.\n",
        "==================================================\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VR0IVg8xl1uZ",
        "outputId": "d53f64d4-9c72-4d81-a685-26b6165f6792"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- Dataset Info ----\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 397 entries, 0 to 396\n",
            "Data columns (total 2 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   DATE        397 non-null    object \n",
            " 1   IPG2211A2N  397 non-null    float64\n",
            "dtypes: float64(1), object(1)\n",
            "memory usage: 6.3+ KB\n",
            "None \n",
            "\n",
            "---- Missing Values ----\n",
            "DATE          0\n",
            "IPG2211A2N    0\n",
            "dtype: int64 \n",
            "\n",
            "Categorical columns: Index(['DATE'], dtype='object') \n",
            "\n",
            "After Scaling:\n",
            "    IPG2211A2N  DATE_1/1/1986  DATE_1/1/1987  DATE_1/1/1988  DATE_1/1/1989  \\\n",
            "0   -1.063349      -0.050252      -0.050252      -0.050252      -0.050252   \n",
            "1   -1.182632      -0.050252      -0.050252      -0.050252      -0.050252   \n",
            "2   -1.717612      -0.050252      -0.050252      -0.050252      -0.050252   \n",
            "3   -2.041574      -0.050252      -0.050252      -0.050252      -0.050252   \n",
            "4   -2.181881      -0.050252      -0.050252      -0.050252      -0.050252   \n",
            "\n",
            "   DATE_1/1/1990  DATE_1/1/1991  DATE_1/1/1992  DATE_1/1/1993  DATE_1/1/1994  \\\n",
            "0      -0.050252      -0.050252      -0.050252      -0.050252      -0.050252   \n",
            "1      -0.050252      -0.050252      -0.050252      -0.050252      -0.050252   \n",
            "2      -0.050252      -0.050252      -0.050252      -0.050252      -0.050252   \n",
            "3      -0.050252      -0.050252      -0.050252      -0.050252      -0.050252   \n",
            "4      -0.050252      -0.050252      -0.050252      -0.050252      -0.050252   \n",
            "\n",
            "   ...  DATE_9/1/2008  DATE_9/1/2009  DATE_9/1/2010  DATE_9/1/2011  \\\n",
            "0  ...      -0.050252      -0.050252      -0.050252      -0.050252   \n",
            "1  ...      -0.050252      -0.050252      -0.050252      -0.050252   \n",
            "2  ...      -0.050252      -0.050252      -0.050252      -0.050252   \n",
            "3  ...      -0.050252      -0.050252      -0.050252      -0.050252   \n",
            "4  ...      -0.050252      -0.050252      -0.050252      -0.050252   \n",
            "\n",
            "   DATE_9/1/2012  DATE_9/1/2013  DATE_9/1/2014  DATE_9/1/2015  DATE_9/1/2016  \\\n",
            "0      -0.050252      -0.050252      -0.050252      -0.050252      -0.050252   \n",
            "1      -0.050252      -0.050252      -0.050252      -0.050252      -0.050252   \n",
            "2      -0.050252      -0.050252      -0.050252      -0.050252      -0.050252   \n",
            "3      -0.050252      -0.050252      -0.050252      -0.050252      -0.050252   \n",
            "4      -0.050252      -0.050252      -0.050252      -0.050252      -0.050252   \n",
            "\n",
            "   DATE_9/1/2017  \n",
            "0      -0.050252  \n",
            "1      -0.050252  \n",
            "2      -0.050252  \n",
            "3      -0.050252  \n",
            "4      -0.050252  \n",
            "\n",
            "[5 rows x 397 columns] \n",
            "\n",
            "Explained Variance Ratio (PCA): [0.00504055 0.00252525] \n",
            "\n",
            "Feature Selection Scores:\n",
            "             Feature     Score\n",
            "32    DATE_1/1/2018  7.071186\n",
            "28    DATE_1/1/2014  5.366585\n",
            "231   DATE_5/1/1985  4.806366\n",
            "232   DATE_5/1/1986  4.662819\n",
            "33   DATE_10/1/1985  4.520652\n",
            "..              ...       ...\n",
            "309   DATE_7/1/1997  0.000660\n",
            "84   DATE_11/1/2003  0.000316\n",
            "83   DATE_11/1/2002  0.000313\n",
            "250   DATE_5/1/2004  0.000141\n",
            "58   DATE_10/1/2010  0.000026\n",
            "\n",
            "[396 rows x 2 columns] \n",
            "\n",
            "\n",
            "==================== SUMMARY ====================\n",
            "Missing values handled using mean imputation (if any).\n",
            "No categorical encoding was needed (dataset fully numeric).\n",
            "Feature scaling applied using StandardScaler (Z-score normalization).\n",
            "PCA reduced dataset to 2 principal components for visualization.\n",
            "Feature selection (SelectKBest) showed importance scores of numeric features.\n",
            "==================================================\n",
            "\n"
          ]
        }
      ]
    }
  ]
}